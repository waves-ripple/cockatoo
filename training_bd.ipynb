{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc26fee-6522-4166-8747-0a3231bfddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: absfly, four, go, happy, house, left, marvin, nine, no, off, on, one, right, seven, six, stop, three, tree, two, up, wow, yes, zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "datadir = \"speech_commands\"\n",
    "\n",
    "samples_by_target = {\n",
    "    cls: [os.path.join(datadir, cls, name) for name in os.listdir(\"./speech_commands/{}\".format(cls))]\n",
    "    for cls in os.listdir(datadir)\n",
    "    if os.path.isdir(os.path.join(datadir, cls))\n",
    "}\n",
    "print('Classes:', ', '.join(sorted(samples_by_target.keys())[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96250255-f7eb-4e1d-97f0-d2871ac0a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e961d7-c01c-4bd9-90a8-cf1e49568565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rand_noise(audio):\n",
    "    background_noises = [\n",
    "        'speech_commands/_background_noise_/white_noise.wav',\n",
    "       'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "       'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "       'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "       'speech_commands/_background_noise_/pink_noise.wav',\n",
    "       'speech_commands/_background_noise_/running_tap.wav'\n",
    "    ]\n",
    "    \n",
    "    noise_num = torch.randint(low=0, high=len(background_noises), size=(1,)).item()    \n",
    "    noise = torchaudio.load(background_noises[noise_num])[0].squeeze()    \n",
    "    \n",
    "    noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "    noise_energy = torch.norm(noise)\n",
    "    audio_energy = torch.norm(audio)\n",
    "    alpha = (audio_energy / noise_energy) * torch.pow(10, -noise_level / 20)\n",
    "\n",
    "    start = torch.randint(low=0, high=int(noise.size(0) - audio.size(0) - 1), size=(1,)).item()\n",
    "    noise_sample = noise[start : start + audio.shape[0]]\n",
    "\n",
    "    audio_new = audio + alpha * noise_sample\n",
    "    audio_new.clamp_(-1, 1)\n",
    "    return audio_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34901b2b-4848-46cf-b1f2-d8e9fc5a838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import distributions\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eefea0c-da67-490e-9be9-52ff6851621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 35\n",
    "N_MELS     = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8f578f-d0e8-401b-9843-11d7f4521780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Custom competition dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root='', csv_path='labels_sheila.csv', kw='sheila', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.kw = kw\n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        utt_name = self.root + self.csv.loc[idx, 'name']\n",
    "        utt = torchaudio.load(utt_name)[0].squeeze()\n",
    "        word = self.csv.loc[idx, 'word']\n",
    "        label = self.csv.loc[idx, 'label']\n",
    "        \n",
    "        if self.transform:\n",
    "            utt = self.transform(utt)\n",
    "\n",
    "        sample = {'utt': utt, 'word': word, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31084fc2-8b6e-4210-aead-9fee902d5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tr(wav):\n",
    "    aug_num = torch.randint(low=0, high=4, size=(1,)).item()\n",
    "    augs = [\n",
    "        lambda x: x,\n",
    "        lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "        lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "        lambda x: add_rand_noise(x)\n",
    "    ]\n",
    "    \n",
    "    return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f94ee1-26e5-4014-b190-00e7d0bf42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all train+val samples: 50972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_dataset = TrainDataset(csv_path='labels.csv', transform=transform_tr)\n",
    "print('all train+val samples:', len(my_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea8a83f-0add-400a-a869-9504057fae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "50967    1\n",
      "50968    1\n",
      "50969    1\n",
      "50970    1\n",
      "50971    1\n",
      "Name: label, Length: 50972, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_len = 44855\n",
    "val_len = 50972 - train_len \n",
    "train_set, val_set = torch.utils.data.random_split(my_dataset, [train_len, val_len])\n",
    "print(train_set.dataset.csv['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a57dd9b6-c3b7-4814-b686-51ee91c352c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bffec00-02c5-48cd-94a5-6f6ed14bef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.dataset.csv['label'][train_set.indices].values)\n",
    "val_sampler   = get_sampler(val_set.dataset.csv['label'][val_set.indices].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed603e42-4414-4a43-b572-79074d1f9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    wavs = []\n",
    "    labels = []    \n",
    "        \n",
    "    for el in data:\n",
    "        wavs.append(el['utt'])\n",
    "        labels.append(el['label'])\n",
    "    wavs = pad_sequence(wavs, batch_first=True)\n",
    "    labels = torch.Tensor(labels).type(torch.long)\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "053f8558-5c49-4533-a5f6-2477506e7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, collate_fn=preprocess_data, \n",
    "                          sampler=train_sampler, drop_last=False,\n",
    "                          num_workers=1, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, collate_fn=preprocess_data, \n",
    "                        sampler=val_sampler, drop_last=False,\n",
    "                        num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4540752e-d58c-4315-bdbd-92708fa981a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "set_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb3bb84-1793-4ad0-9fc8-d0fbb0b5f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f4193c3-b920-48ec-952a-0c255a1fc99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5235c02c-2eb3-4baf-8c59-92c8d4ffb183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f75bc4-8623-4cf0-813a-3bcf5e140856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with augmentations\n",
    "melspec_train = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000,  n_mels=N_MELS),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# no augmentations\n",
    "melspec_val = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=N_MELS\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39bdc069-4992-4cee-9934-0a77caee98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    return FA.item()/torch.numel(preds), FR.item()/torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52617e2b-d520-49d1-b4e0-0b81e5796f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_SIZE = 40\n",
    "HIDDEN_SIZE = 128\n",
    "KERNEL_SIZE = (20, 5)\n",
    "STRIDE = (8, 2)\n",
    "GRU_NUM_LAYERS = 2\n",
    "NUM_DIRS = 2\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b811da-ae70-443f-9bf9-fa4b5e418567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepconv(in_size, out_size, kernel_size, stride=1, dilation=1, padding=0):\n",
    "    return nn.Sequential(\n",
    "        torch.nn.Conv1d(in_size, in_size, kernel_size[1], \n",
    "                        stride=stride[1], dilation=dilation, groups=in_size,\n",
    "                        padding=padding),\n",
    "        \n",
    "        torch.nn.Conv1d(in_size, out_size, kernel_size=1, \n",
    "                        stride=stride[0], groups=int(in_size/kernel_size[0])),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "534e6915-ac0d-43e3-afe5-c3b843df4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, kernel_size, stride, gru_nl, ):\n",
    "        super(CRNN, self).__init__()\n",
    "          \n",
    "        self.sepconv = sepconv(in_size=in_size, out_size=hidden_size, kernel_size=kernel_size, stride=stride)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=gru_nl, dropout=0.1, bidirectional=True)\n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.sepconv(x)\n",
    "        \n",
    "        # (BS, HS, ?) -> (HS, BS, ?) ->(seq_len, BS, HS)\n",
    "        x = x.transpose(0, 1).transpose(0, 2)\n",
    "        \n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        # x : (seq_len, BS, HS * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, HS)\n",
    "                        \n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b2a083-1259-4985-987d-3651d354e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyAttn(nn.Module):\n",
    "    def __init__(self, in_size, num_classes):\n",
    "        super(ApplyAttn, self).__init__()\n",
    "        self.U = nn.Linear(in_size, num_classes, bias=False)\n",
    "        \n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, e, data):\n",
    "        data = data.transpose(0, 1)           # (BS, seq_len, hid_size*num_dirs)\n",
    "        a = F.softmax(e, dim=-1).unsqueeze(1)\n",
    "        c = torch.bmm(a, data).squeeze()\n",
    "        Uc = self.U(c)        \n",
    "        return F.log_softmax(Uc, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "375e43e5-6f00-4ea8-a696-7d4f5462b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, CRNN_model, attn_layer, apply_attn):\n",
    "        super(FullModel, self).__init__()\n",
    "        \n",
    "        self.CRNN_model = CRNN_model\n",
    "        self.attn_layer = attn_layer\n",
    "        self.apply_attn = apply_attn\n",
    "\n",
    "        \n",
    "    def forward(self, batch, hidden):\n",
    "        output, hidden = self.CRNN_model(batch, hidden)\n",
    "        # output: (seq_len, BS, hidden*num_dir)\n",
    "        \n",
    "        e = []\n",
    "        for el in output:\n",
    "            e_t = self.attn_layer(el)       # -> (BS, 1)\n",
    "            e.append(e_t)\n",
    "        e = torch.cat(e, dim=1)        # -> (BS, seq_len)\n",
    "        \n",
    "        probs = self.apply_attn(e, output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bcfbf44-f384-4ca1-a544-18387aa8e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnMech(nn.Module):\n",
    "    def __init__(self, lin_size):\n",
    "        super(AttnMech, self).__init__()\n",
    "        \n",
    "        self.Wx_b = nn.Linear(lin_size, lin_size)\n",
    "        self.Vt   = nn.Linear(lin_size, 1, bias=False)\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.Wx_b(x))\n",
    "        e = self.Vt(x)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48e98b1c-9841-4f1b-bb34-36f73f467a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel(\n",
      "  (CRNN_model): CRNN(\n",
      "    (sepconv): Sequential(\n",
      "      (0): Conv1d(40, 40, kernel_size=(5,), stride=(2,), groups=40)\n",
      "      (1): Conv1d(40, 128, kernel_size=(1,), stride=(8,), groups=2)\n",
      "    )\n",
      "    (gru): GRU(128, 128, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  )\n",
      "  (attn_layer): AttnMech(\n",
      "    (Wx_b): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (Vt): Linear(in_features=256, out_features=1, bias=False)\n",
      "  )\n",
      "  (apply_attn): ApplyAttn(\n",
      "    (U): Linear(in_features=256, out_features=2, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CRNN_model = CRNN(IN_SIZE, HIDDEN_SIZE, KERNEL_SIZE, STRIDE, GRU_NUM_LAYERS)\n",
    "attn_layer = AttnMech(HIDDEN_SIZE * NUM_DIRS)\n",
    "apply_attn = ApplyAttn(HIDDEN_SIZE * 2, NUM_CLASSES)\n",
    "\n",
    "full_model = FullModel(CRNN_model, attn_layer, apply_attn)\n",
    "writer  = SummaryWriter('runs/experiment_2')\n",
    "print(full_model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75ba3a94-f981-47a0-8132-7c143003909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels, device):\n",
    "    sorted_probs, indices = torch.sort(probs)\n",
    "\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]).to(device), sorted_probs))\n",
    "    sorted_probs = torch.cat((sorted_probs, torch.Tensor([1]).to(device)))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        ones = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(ones, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4ef1478-287d-4cf7-a9b4-54b4b1828676",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(full_model.parameters(), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1426b67-7396-4522-aa5b-f6ed4fe1949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, melspec, gru_nl, hidden_size, epoch, device):\n",
    "    model.train()\n",
    "    loss = None\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = torch.log(melspec(batch) + 1e-9).to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # define frist hidden with 0\n",
    "        hidden = torch.zeros(gru_nl*2, batch.size(0), hidden_size).to(device)    # (num_layers*num_dirs,  BS, HS)\n",
    "        # run model\n",
    "        probs = model(batch, hidden)\n",
    "        loss = F.nll_loss(probs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)                \n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.true_divide(\n",
    "                            torch.sum(argmax_probs == labels), \n",
    "                            torch.numel(argmax_probs)\n",
    "        )\n",
    "        #wandb.log({'loss':loss.item(), 'train_FA':FA, 'train_FR':FR, 'train_acc':acc})\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(loader) + i)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e3d7426-b72a-42f8-a4e5-65170c781f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, filename=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d85f910-4e11-4830-a4f6-ca6292862e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, melspec, gru_nl, hidden_size, epoch, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses, accs, FAs, FRs = [], [], [], []\n",
    "        all_probs, all_labels = [], []\n",
    "        for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            batch = torch.log(melspec(batch) + 1e-9).to(device)  \n",
    "\n",
    "            # define frist hidden with 0\n",
    "            hidden = torch.zeros(gru_nl*2, batch.size(0), hidden_size).to(device)    # (num_layers*num_dirs,  BS, HS)\n",
    "            # run model\n",
    "            probs = model(batch, hidden)\n",
    "            loss = F.nll_loss(probs, labels)\n",
    "            \n",
    "            # logging\n",
    "            argmax_probs = torch.argmax(probs, dim=-1)\n",
    "            all_probs.append(torch.exp(probs)[:, 1])\n",
    "            all_labels.append(labels)\n",
    "            val_losses.append(loss.item())\n",
    "            accs.append(torch.true_divide(\n",
    "                                torch.sum(argmax_probs == labels), \n",
    "                                torch.numel(argmax_probs)).item()\n",
    "                       )\n",
    "\n",
    "            FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "            FAs.append(FA)\n",
    "            FRs.append(FR)\n",
    "            \n",
    "        # area under FA/FR curve for whole loader\n",
    "        au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0), all_labels, device)    \n",
    "        writer.add_scalar('Accuracy/train', np.mean(accs), epoch * len(loader) + i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "846aa25b-ba13-45dd-9c06-97336c202b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.34it/s]\n",
      "24it [00:07,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 0\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34905/1323824996.py:16: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return -np.trapz(FRs, x=FAs)\n",
      "176it [00:53,  3.27it/s]\n",
      "24it [00:07,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 1\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:54,  3.26it/s]\n",
      "24it [00:07,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 2\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.36it/s]\n",
      "24it [00:07,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 3\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:55,  3.19it/s]\n",
      "24it [00:07,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 4\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:51,  3.40it/s]\n",
      "24it [00:07,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 5\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:56,  3.14it/s]\n",
      "24it [00:07,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 6\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:54,  3.20it/s]\n",
      "24it [00:07,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 7\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:56,  3.10it/s]\n",
      "24it [00:07,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 8\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:54,  3.22it/s]\n",
      "24it [00:07,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 9\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.31it/s]\n",
      "24it [00:07,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 10\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.32it/s]\n",
      "24it [00:07,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 11\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.27it/s]\n",
      "24it [00:07,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 12\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.26it/s]\n",
      "24it [00:07,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 13\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.36it/s]\n",
      "24it [00:07,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 14\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.27it/s]\n",
      "24it [00:07,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 15\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.30it/s]\n",
      "24it [00:07,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 16\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.30it/s]\n",
      "24it [00:07,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 17\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.35it/s]\n",
      "24it [00:07,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 18\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.30it/s]\n",
      "24it [00:07,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 19\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.29it/s]\n",
      "24it [00:07,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 20\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.35it/s]\n",
      "24it [00:07,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 21\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.26it/s]\n",
      "24it [00:07,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 22\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:54,  3.20it/s]\n",
      "24it [00:07,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 23\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.30it/s]\n",
      "24it [00:07,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 24\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.38it/s]\n",
      "24it [00:07,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 25\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.33it/s]\n",
      "24it [00:07,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 26\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.28it/s]\n",
      "24it [00:07,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 27\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:55,  3.16it/s]\n",
      "24it [00:07,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 28\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.26it/s]\n",
      "24it [00:07,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 29\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:54,  3.24it/s]\n",
      "24it [00:07,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 30\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.27it/s]\n",
      "24it [00:07,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 31\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:55,  3.16it/s]\n",
      "24it [00:07,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 32\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:53,  3.26it/s]\n",
      "24it [00:07,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 33\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:52,  3.34it/s]\n",
      "24it [00:07,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 34\n",
      "Checkpoint saved: checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "for n in range(NUM_EPOCHS):\n",
    "    \n",
    "    loss = train_epoch(full_model, opt, train_loader, melspec_train, \n",
    "          GRU_NUM_LAYERS, HIDDEN_SIZE, n, device=device)           \n",
    "\n",
    "\n",
    "    validation(full_model, val_loader, melspec_val, \n",
    "        GRU_NUM_LAYERS, HIDDEN_SIZE, n, device=device)\n",
    "\n",
    "    print('END OF EPOCH', n)\n",
    "    if n % 1 == 0:\n",
    "        save_checkpoint(full_model, opt, n, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7291b9-c80e-4c55-9064-78ab2d2b0e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f582a6c-3751-47cc-9a1b-cf95dc2b8b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b655e-2b2e-4e19-9415-b5de09721ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c80b62-fd01-4d4e-938a-b3a3b99c5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6f793-d6b6-4cf1-b0fc-d93899fcfdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e851247-4699-42a3-a43f-26a7a76d4561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed7092-e0cf-4c9b-b655-d1bf71e91e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ceedb-d77e-4b20-b807-56de5650aaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69c228-56cc-40ee-a688-d9c4a6ce26ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f402c0-1107-4dc2-adc5-ce882943beb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b34c6-b365-4a94-a5fc-4b82c3062e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ed2bd-4c39-46d0-a2cd-e85339f457df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59824c43-8b45-44b5-af6d-3d98185cfef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af787fd2-fd41-40ff-b2f8-e509a15660c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b9ddf-b149-4b34-b773-a29074b2d621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce4123-3613-4064-81ec-3d4cd9e90e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bab029-fe0e-43f0-9c0d-1eb49fde9127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
